{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to work on the files:\n",
    "*  [Books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz)\n",
    "*  [Book ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz)\n",
    "*  [Users](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz)\n",
    "*  [Goodbooks books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz)\n",
    "*  [Goodbooks ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz)\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    To read those files, you need to use the `encoding = 'latin-1'` option.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com), otherwise no  answer will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di _Foundations of Computer Science_\n",
    "\n",
    "Camagni Valentina(878252), Grosso Silvia (881993), Merelli Elisa (881427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerie\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo i dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz\", compression = 'gzip',  encoding = 'latin_1', sep=\";\", low_memory = False,\n",
    "                     escapechar= '\\\\',dtype = {'Year-Of-Publication':'int64'})\n",
    "\n",
    "#parametri encoding richiesto e compression necessario perchè file .gz da decomprimere\n",
    "#low_memory = false per warning del codice (var booleana)\n",
    "#aggiungo dtype come verifica per i campi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungendo l'escape character '\\\\' in books non ho errore in questo record (errore segnalato grazie a dtype)\n",
    "books.loc[209538]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz\",compression='gzip', encoding = 'latin-1', sep=\";\", \n",
    "                      dtype = {'User-ID':'int64',\n",
    "                              'Book-Rating':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz\",compression='gzip', encoding = 'latin-1', sep=\";\", \n",
    "                   dtype = {'User-ID': 'int64',\n",
    "                            'Age':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz\",compression='gzip', encoding = 'latin-1', sep=\",\",\n",
    "                      dtype= {range(1,5) :'int64', \n",
    "                              'original_publication_year':'float64',\n",
    "                              'average_rating':'float64',\n",
    "                              'ratings_count':'int64', \n",
    "                              'work_ratings_count':'int64', \n",
    "                              'work_text_reviews_count':'int64',\n",
    "                              'ratings_1':'int64',\n",
    "                              'ratings_2':'int64', \n",
    "                              'ratings_3':'int64',\n",
    "                              'ratings_4':'int64', \n",
    "                              'ratings_5':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books[['book_id','average_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rat = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz\",compression='gzip', encoding = 'latin-1', sep=\",\",\n",
    "                    dtype= {range(1,3):'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esploriamo i dati appena caricati, analizzando dimensioni e attributi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookrat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookrat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalize the location field of *Users* dataset, splitting into city, region, country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo osservato che in *Location* le stringhe sono separate da virgola e spazio. Utilizzo il metodo split specificando l'espressione regolare di separazione in pat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split=users['Location'].str.split(pat = ',\\s', expand=True)\n",
    "split[split[8].isna()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che di default vengono create 9 colonne poichè, evidentemente, vi sono records di *users* con più campi relativamente alla *Location*. Decidiamo di definire attraverso una regex il formato *Location* che desideriamo. Gli *users* che non soddisfano tale pattern non verranno considerati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users=users[users['Location'].str.match(\"^([a-zA-Z\\.\\s\\/-]+|\"\"),([a-zA-Z\\.\\s\\/-]+|\"\"),([a-zA-Z\\.\\s\\/-]+|\"\")$\")== True].reset_index(drop=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splittiamo la colonna Location nei 3 campi *City, Region, Country*, richiesti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users[['City','Region','Country']]=users['Location'].str.split(',\\s', expand=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopodiché definiamo un nuovo dataframe *users_normalize* dove rimuoviamo la colonna *Location*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_normalize = users.drop('Location', 1) ## ',1' per dire colonna\n",
    "users_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each book in the *Books* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osservando i dataset abbiamo visto che in *bookrat* ci sono più righe riferite allo stesso ISBN perchè corrispondenti alle valutazioni di *'user_id'* differenti. Raggruppiamo quindi per ISBN e calcoliamo la media di rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat.groupby('ISBN').mean()['Book-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#verifico calcolo per secondo ISBN \n",
    "bookrat[bookrat['ISBN'] == '0375404120']\n",
    "\n",
    "#qui la media dovrebbe essere 18/7=2.57 -> errore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'è un errore nel calcolo della media: individuiamo quindi le righe contenenti la stringa '0375404120' nella colonna ISBN con il metodo str.contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookrat[bookrat['ISBN'].str.contains('0375404120')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi sono più righe che contengono questo ISBN rispetto alla ricerca precedente: deduciamo che la presenza di spazi all'inizio e alla fine della stringa ha compromesso i risultati. Infatti verifichiamo che inserendo uno spazio all'inizio della stringa torna il risultato mostrato nella colonna Book-Rating iniziale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookrat[bookrat['ISBN'].str.contains('\\s0375404120')]  \n",
    "#aggiungendo uno spazio davanti ottengo solo più due righe (corrispondo al primo calcolo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tolgo quindi gli spazi a capo e coda della stringa ISBN sia in *books* che in *bookrat* con il metodo str.strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.ISBN = books.ISBN.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat.ISBN = bookrat.ISBN.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo applicare il metodo groupby sugli ISBN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bookrat_avg = bookrat.groupby('ISBN', as_index= False).mean()[['ISBN','Book-Rating']]\n",
    "bookrat_avg.head()\n",
    "\n",
    "#as_index= False per togliere ISBN come indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuiamo ora il merge dei due dataframe sull'ISBN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_bookrat_avg = pd.merge(books,bookrat_avg, on = 'ISBN', how = 'left')\n",
    "books_bookrat_avg['Book-Rating'] = books_bookrat_avg['Book-Rating'].round(2)   #arrotondo la media a 2 cifre decimali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_bookrat_avg[['ISBN','Book-Title', 'Book-Author','Book-Rating']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each book in the *GoodBooks* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_books.columns\n",
    "#mostro tutte le colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si osserva che è presente la colonna contenente le valutazioni medie per ogni libro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_books[['book_id','isbn','original_title', 'average_rating']].set_index('book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo che i valori nella colonna *'average_rating'* corrispondano alla media pesata del numero di persone che hanno votato 1:5 ('ratings_i') sul numero totale, corrispondente a 'work_ratings_count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo che la somma dei ratings sia sempre corrispondente a work_ratings_count con una condizione booleana\n",
    "gb_books[(gb_books['work_ratings_count'] == gb_books['ratings_1']+gb_books['ratings_2']+gb_books['ratings_3']+gb_books['ratings_4']+gb_books['ratings_5']) == False].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#verifico ora la corrispondenza dei valori delle medie\n",
    "gb_books[((((gb_books['ratings_1']*1 + gb_books['ratings_2']*2 + gb_books['ratings_3']*3 + gb_books['ratings_4']*4 + gb_books['ratings_5']*5) / gb_books['work_ratings_count']).round(2) == gb_books['average_rating'])) == False].count()\n",
    "\n",
    "#effettivamente le medie calcolate manualmente corrispondono alla colonna dell'average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge together all rows sharing the same book title, author and publisher. We will call the resulting datset `merged books`. The books that have not been merged together will not appear in `merged books`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innanzitutto effettuiamo un groupby su *'Book-Title','Book-Author','Publisher'*, individuando i conteggi uguali o superiori a 2, corrispondenti ai *merged books*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcolo numero di righe con stesso book title, author, publisher\n",
    "merge = books.groupby(['Book-Title','Book-Author','Publisher'], as_index= False).count()\n",
    "#as_index= False per avere un indice implicito e mantenere le stesse colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo quindi solo i libri comparsi almeno 2 volte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_books = merge[merge['ISBN'] > 1]\n",
    "merged_books = merged_books[['Book-Title','Book-Author','Publisher','ISBN']].rename({'ISBN':'Count'}, axis = 1)\n",
    "#rinomino 'ISBN' con 'count'\n",
    "merged_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_books)\n",
    "# I libri con stesso titolo, autore e editore sono 4725."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For each book in `merged books` compute its average rating.\n",
    "\n",
    "The average is computed considering all books in `books` that have been merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unisco tabelle *books* e *bookrat* con ISBN chiave primaria di books, già corretti precedentemente con strip(), per accertarmi di avere tutto l'elenco di books con valutazioni distinte per isbn e utente (*users-id*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_bookrat = pd.merge(books, bookrat, on = 'ISBN', how = 'left')\n",
    "books_bookrat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuiamo ora un left join su 'Book-Title','Book-Author','Publisher' tra la tabella *merged_books* e *books_bookrat* ottenuta precedentemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_books_bookrat = pd.merge(merged_books[['Book-Title','Book-Author','Publisher']], books_bookrat, on = ['Book-Title','Book-Author','Publisher'], how= 'left')\n",
    "merged_books_bookrat.head()\n",
    "\n",
    "#ottengo tabella con tutti i books che sono presenti in merged_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_books_bookrat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo un numero maggiore di records. Infatti lo stesso libro individuato da *'Book-Title','Book-Author','Publisher'* può avere edizioni e quindi ISBN differenti e, per ogni edizione, valutazioni da utenti differenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo ora, per ogni libro in *merged_books*, la media di valutazioni, raggruppando anche per ISBN/edizioni differenti.\n",
    "In questa tabella potremo sapere, per ogni libro che ha avuto più edizioni, la valutazione media di ogni singola edizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books_avg = merged_books_bookrat.groupby(['Book-Title','Book-Author','Publisher','ISBN'], as_index= False).mean().round(2)\n",
    "merged_books_avg[['Book-Title','Book-Author','Publisher','Book-Rating','ISBN']].rename({'Book-Rating':'Avg-Rating'}, axis = 1)\n",
    "#abbiamo ottenuto un numero maggiore del numero di libri in merged_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each book in `merged books` compute the minimum and maximum of the average ratings over all corresponding books in the `books` dataset.\n",
    "\n",
    "Hence for each book in `merged books` we will have exactly two values (a minimum and a maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmin = merged_books_avg.groupby(['Book-Title','Book-Author','Publisher'], as_index = False).min()[['Book-Title','Book-Author','Publisher','Book-Rating']].rename({'Book-Rating':'Min-Rating'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriemax = merged_books_avg.groupby(['Book-Title','Book-Author','Publisher'], as_index = False).max()['Book-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dfmin,seriemax], axis = 1).reset_index(drop= True).rename({'Book-Rating':'Max-Rating'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each book in `merged books` compute the minimum and maximum of the average ratings over all corresponding books in the `books` dataset.\n",
    "\n",
    "Hence for each book in `merged books` we will have exactly two values (a minimum and a maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo la media di rating per ogni edizione (ISBN) di tutti i libri, distinti da *'Book-Title','Book-Author','Publisher'*,  in *books*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rat_ISBN = books_bookrat.groupby(['Book-Title','Book-Author','Publisher','ISBN'],as_index= False).mean().rename({'Book-Rating':'Avg-Rating'}, axis = 1)\n",
    "avg_rat_ISBN = avg_rat_ISBN[['Book-Title','Book-Author','Publisher','ISBN','Avg-Rating']].round(2)\n",
    "avg_rat_ISBN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rat_ISBN.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una nuova tabella *extreme_rat* contentente, per ogni libro presente in *merged_books*, l'avg-rating associato a ogni edizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extreme_rat = pd.merge(merged_books, avg_rat_ISBN, on = ['Book-Title', 'Book-Author', 'Publisher'], how = 'left')\n",
    "extreme_rat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraiamo quindi, per ogni singolo libro (title,author,publisher), il min e il massimo della media delle valutazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriemin = extreme_rat.groupby(['Book-Title', 'Book-Author', 'Publisher']).min().rename({'Avg-Rating':'Min-Rating'}, axis = 1)['Min-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriemax = extreme_rat.groupby(['Book-Title', 'Book-Author', 'Publisher']).max().rename({'Avg-Rating':'Max-Rating'}, axis = 1)['Max-Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conteggiamo infine il numero di edizioni per ogni libro (title,author,publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriecount = extreme_rat.groupby(['Book-Title', 'Book-Author', 'Publisher']).count().rename({'Avg-Rating':'Conteggio'}, axis = 1)['Conteggio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo quindi la tabella definitiva: \n",
    "ad ogni libro (title,author,publisher) è associato il minimo e massimo di avg-rating e il numero di edizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([seriemin,seriemax, seriecount], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For each book in `goodbooks`, compute the list of its authors. Assuming that the number of reviews with a text (column `work_text_reviews_count`) is split equally among all authors, find for each authors the total number of reviews with a text. We will call this quantity the *shared number of reviews with a text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creo una lista degli autori\n",
    "lista_autori = gb_books.authors.str.split(', ').tolist()\n",
    "lista_autori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un dizionario che abbia come chiavi i valori contenuti nella colonna *'book_id'* di *gb_books*, e come valore una lista contenente gli autori del libro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "libri_autori = {}\n",
    "\n",
    "for i in list(gb_books['book_id']):\n",
    "    libri_autori[i] = lista_autori[i-1]\n",
    "                                # [i-1] perchè bookid parte da 1, l'indice implicito parte da 0\n",
    "    \n",
    "libri_autori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seconda parte dell'esercizio richiede di calcolare, per ogni autore il numero totale di reviews with a text, che chiameremo *shared number of reviews with a text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ricavo lista autori singoli ordinati(sorted) e non ripetuti(set) sommando tutte le liste presenti in lista_autori\n",
    "singoli_autori = sorted(set(sum(lista_autori, [])))\n",
    "singoli_autori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creo la serie rev:\n",
    "#partendo dai valori nella colonna work_text_reviews_count, divido ogni singolo valore per il numero di autori associati.\n",
    "#Ottengo così rev come serie di rev partizionate equamente ad ogni libro in gb_books\n",
    "\n",
    "rev = gb_books['work_text_reviews_count'].copy()\n",
    "for i in range(len(rev)):\n",
    "    rev[i] = rev[i]/len(libri_autori[i+1])\n",
    "                                    #[i+1] perchè rev parte da 0 e libri_autori da 1\n",
    "rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottenuta così la colonna con il numero di work_text_reviews suddivise per ogni autore, creo un dizionario che associa a ciascun autore lo \"shared number of reviews with a text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(libri_autori è il dizionario con liste di autori per ogni book_id)\n",
    "shared_num_rev = {}\n",
    "for autore in singoli_autori:\n",
    "    shared_num_rev[autore] = 0\n",
    "    for i in libri_autori:\n",
    "        if autore in libri_autori[i]:\n",
    "            shared_num_rev[autore] += rev[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shared_num_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each year of publication, determine the author that has the largest value of the shared number of reviews with a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una lista senza ripetizioni di tutti gli anni\n",
    "years = list(set(gb_books['original_publication_year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dizionario con chiave *original_publication_year* e valori la lista di tutti gli autori dei libri con quell'anno di pubblicazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_authors = {}\n",
    "\n",
    "for year in years:\n",
    "    year_authors[year] = []\n",
    "    for i in gb_books.book_id:\n",
    "        if gb_books.original_publication_year[i-1] == year:\n",
    "            year_authors[year] += gb_books.authors[i-1].split(', ')\n",
    "        \n",
    "year_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo un nuovo dizionario: ad ogni chiave corrispondente a *original_pubblication_year* verrà associato l'autore corrispondente con il numero massimo di *shared_num_rev*;  sarà una lista di autori in caso di parimerito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anno_max_rev = {}\n",
    "for year in year_authors:\n",
    "    massimo = 0\n",
    "    anno_max_rev[year] = []\n",
    "    for author in year_authors[year]:\n",
    "        if shared_num_rev[author]>= massimo:\n",
    "            massimo = shared_num_rev[author]\n",
    "            anno_max_rev[year] += [author]\n",
    "    \n",
    "anno_max_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Assuming that there are no errors in the ISBN fields, find the books in both datasets, and compute the difference of average rating according to the ratings and the goodratings datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo con *diff_avg* l'inner join tra il dataset *books_bookrat_avg* (contenente per ogni libro di *books* il rating medio) e *gb_books* (contenente per ogni libro l'*average rating*). La differenza dell'average rating è calcolata dalla semplice differenza dei valori delle due colonne per ogni libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_avg = pd.merge(books_bookrat_avg, gb_books, left_on='ISBN', right_on='isbn')\n",
    "diff_avg['diff-avg'] = diff_avg['Book-Rating'] - diff_avg['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_avg[['ISBN','Book-Title','Year-Of-Publication','Publisher','Book-Rating','average_rating','diff-avg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Split the users dataset according to the age. One dataset contains the users with unknown age, one with age 0-14, one with age 15-24, one with age 25-34, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo per ogni fascia d'età un dataframe nuovo ottenuto come filtraggio di *users* in base al range d'età "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creaimo innanzitutto il DataFrame contenente gli users con età sconosciuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_unknown = users[users['Age'].isna()].reset_index(drop=True)\n",
    "df_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo la lista con i ranges d'età:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.Age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranges= [-1]+[i for i in range(14,int(users.Age.max())+1,10)]\n",
    "ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo il dizionario le cui chiavi sono i nomi dei DataFrame distinti per età, e i valori sono i DataFrame contenenti l'insieme dei record degli users filtrati per età associata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta = {}\n",
    "for i in range(0,len(ranges)-1):\n",
    "    classi_eta[\"df_{0}\".format(ranges[i+1])] = users[(users['Age']>ranges[i])&(users['Age']<=ranges[i+1])].sort_values('Age').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta['df_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta['df_244']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Find the books that appear only in the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottenere i libri il cui isbn appare solamente nel dataset *gb_books* e non nel dataset *books*, eseguo l'equivalente in pandas del not in in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books[~ gb_books['isbn'].isin(books['ISBN'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Assuming that each pair (author, title) identifies a book, for each book find the number of times it appears in the books dataset. Which books appear the most times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raggruppiamo in *times* i records del dataset *books* con la coppia di attributi *'Book-Title','Book-Author'* e ne contiamo la numerosità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "times = books.groupby(['Book-Title','Book-Author'], as_index = False).count()[['Book-Title','Book-Author','ISBN']].rename({'ISBN':'Count'}, axis = 1)\n",
    "times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo quindi la coppia che appare il maggior numero di volte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times.iloc[times['Count'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[times['Count'] == times['Count'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Find the author with the highest average rating according to the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un dizionario che associ ad ogni autore tutti i *book_id* in cui è presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autori_libri = {}\n",
    "\n",
    "for autore in singoli_autori:\n",
    "    autori_libri[autore] = []\n",
    "    for book_id in libri_autori:\n",
    "        if autore in libri_autori[book_id]:\n",
    "            autori_libri[autore] += [book_id]      \n",
    "autori_libri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associamo ora a ogni autore i valori di *avg_rating* di ogni suo libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "high_avg_au = {}\n",
    "for autore in singoli_autori:\n",
    "    high_avg_au[autore] = []\n",
    "    for i in autori_libri[autore]:\n",
    "        high_avg_au[autore] += [gb_books.average_rating[i-1]]\n",
    "high_avg_au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concludiamo calcolando per ogni autore la media di *avg_rating* complessiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rating = {}\n",
    "for autore in high_avg_au:\n",
    "    avg_rating[autore] = np.mean(high_avg_au[autore]).round(2)\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuiamo l'autore con massimo valore di *avg_rating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_key = max(avg_rating, key=avg_rating. get)\n",
    "max_key, max(avg_rating.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
